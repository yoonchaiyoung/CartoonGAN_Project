{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"과정_loss.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM4WHao+Qkhwaz2AlS18tVe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hXBTvgdRn08z"},"source":["# adversarial loss\r\n","- 목적 : 사진 매니폴드 -> 타겟(만화) 매니폴드로 mapping을 잘 하는 것\r\n","- $\\large{L_{adv}(G, D) = \\mathbb{E}_{c_{i}∼S_{data}(c)} [log D(c_{i})] \r\n","\\\\ + \\mathbb{E}_{e_{j}∼S_{data}(e)} [log(1 − D(e_{j}))] \r\n","\\\\ + \\mathbb{E}_{p_{k}∼S_{data}(p)} [log(1 − D(G(p_{k})))]}$\r\n","\r\n","- 만화 이미지의 loss + 엣지 smoothing된 만화 이미지의 loss + 카툰화된 사진의 loss"]},{"cell_type":"code","metadata":{"id":"zPGUQpUhokHT"},"source":["def adversarial_loss(disc_c, disc_e, disc_p):\r\n","  \"\"\"\r\n","  ----------------------------------------------\r\n","  파라미터 설명\r\n","  ----------------------------------------------\r\n","  disc_c : 만화 이미지가 discriminator를 통과해서 얻은 출력값(예측값)\r\n","  disc_e : 엣지 smoothing된 만화 이미지가 discriminator를 통과해서 얻은 출력값(예측값)\r\n","  disc_p : 카툰화된 사진이 discriminator를 통과해서 얻은 출력값(예측값)\r\n","  ----------------------------------------------\r\n","  \"\"\"\r\n","\r\n","  # binary cross entropy 객체\r\n","  bce = keras.losses.BinaryCrossentropy()\r\n","  cartoon_error = bce(np.ones_like(disc_c, dtype=tf.float32), disc_c).numpy()\r\n","  edge_smooth_cartoon_error = bce(np.zeros_like(disc_e, dtype=tf.float32), disc_e).numpy()\r\n","  photo_error = bce(np.zeros_like(disc_p, dtype=tf.float32), disc_p).numpy()\r\n","  \r\n","  adv_loss = cartoon_error + edge_smooth_cartoon_error + photo_error\r\n","\r\n","  return adv_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"05HrQcrwoTo_"},"source":["# content loss\r\n","- 목적 : 사진의 semantic content를 유지하는 것\r\n","- $\\large{\\mathcal{L}_{con}(G, D) = \\mathbb{E}_{p_{i}∼S_{data}(p)} [||VGG_{l}(G(p_{i})) − VGG_{l}(p_{i})||_{1}]}$\r\n","\r\n","- VGG19의 고수준 feature map인 conv4_4의 feature map을 사용\r\n","- 전이학습으로 학습"]},{"cell_type":"code","metadata":{"id":"5cfOsVVOpGAr"},"source":["def content_loss(photo_path, cartoonized_photo_path):\r\n","  # ------------------------------------------------------------------------------------------------------------------------------\r\n","  \r\n","  def vgg_transfer_model():\r\n","    \"\"\"\r\n","    -------------------------------------\r\n","    함수 설명\r\n","    -------------------------------------\r\n","    VGG19 모델을 전이학습을 하기 위해서\r\n","    conv4_4 layer까지 불러온다.\r\n","    -------------------------------------\r\n","    \"\"\"\r\n","\r\n","    vgg19 = VGG19()\r\n","    input_shape = (224, 224, 3)\r\n","    input_layer = Input(shape = input_shape)\r\n","    net = vgg19.layers[0](input_layer)\r\n","    net = vgg19.layers[1](net)\r\n","    net = vgg19.layers[2](net)\r\n","    net = vgg19.layers[3](net)\r\n","    net = vgg19.layers[4](net)\r\n","    net = vgg19.layers[5](net)\r\n","    net = vgg19.layers[6](net)\r\n","    net = vgg19.layers[7](net)\r\n","    net = vgg19.layers[8](net)\r\n","    net = vgg19.layers[9](net)\r\n","    net = vgg19.layers[10](net)\r\n","    net = vgg19.layers[11](net)\r\n","    net = vgg19.layers[12](net)\r\n","    net = vgg19.layers[13](net)\r\n","    net = vgg19.layers[14](net)\r\n","    net = vgg19.layers[15](net)\r\n","\r\n","    model = Model(inputs = input_layer,\r\n","                  outputs = net,\r\n","                  name = \"vgg_layer_0to15\")\r\n","    \r\n","    return model\r\n","  \r\n","  # ------------------------------------------------------------------------------------------------------------------------------\r\n","\r\n","  def vgg19_transfer_learning(img_path, model):\r\n","    \"\"\"\r\n","    --------------------------------------------------\r\n","    파라미터 설명\r\n","    --------------------------------------------------\r\n","    img_path : 원본 사진 또는 카툰화된 사진이 저장된 디렉토리 경로\r\n","    model : VGG19 모델의 conv4_4 layer까지의 모델\r\n","    --------------------------------------------------\r\n","    함수 설명\r\n","    --------------------------------------------------\r\n","    VGG19 모델을 가져다가 conv4_4 layer까지 전이학습을 시키는 과정\r\n","    함수의 input : 원본 사진 또는 카툰화된 사진\r\n","    함수의 output : 원본 사진 또는 카툰화된 사진을 VGG19 모델에 통과시킨후\r\n","                    얻은 conv4_4 layer의 feature map\r\n","    --------------------------------------------------\r\n","    \"\"\"\r\n","    \r\n","    imageName_list = os.listdir(img_path)\r\n","\r\n","    feature_map_list = []\r\n","    # VGG19 모델의 conv4_4 layer의 feature map을 각각의 이미지에 대해 구한 후\r\n","    # 리스트에 순서대로 담는다.\r\n","    \r\n","    for imageName in imageName_list:\r\n","      # 이미지 전처리 과정\r\n","      img_bgr = cv2.imread(img_path + '/' + imageName)\r\n","      img = cv2.cvtCOLOR(img_bgr, cv2.COLOR_BGR2RGB)\r\n","      img_resizing = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_LINEAR)\r\n","      img_array = np.asarray(img_resizing)\r\n","      img_4D = img_array.reshape((1, img_array.shape[0], img_array.shape[1], img_array.shape[2]))\r\n","      img_preprocess_input = preprocess_input_img_4D\r\n","      img_float32 = tf.cast(img_preprocess_input, dtype = tf.float32)\r\n","      \r\n","      # VGG19 conv4_4 layer에 해당하는 feature map 추출하기\r\n","      vgg_conv4_4_output = model(img_float32)\r\n","      feature_map_list.append(vgg_conv4_4_output)\r\n","      \r\n","    return feature_map_list\r\n","\r\n","  def l1_regularization(photo_feature_map_list, cartoonized_photo_feature_map_list):\r\n","    \"\"\"\r\n","    ---------------------------------------\r\n","    파라미터 설명\r\n","    ---------------------------------------\r\n","    photo_feature_map_list : 원본 사진 모음의 VGG19 conv4_4 layer의\r\n","                            feature map이 담긴 리스트 \r\n","    cartoonized_photo_feature_map_list : 카툰화된 사진 모음의 VGG19 conv4_4 layer의\r\n","                            feature map이 담긴 리스트 \r\n","    ---------------------------------------\r\n","    함수 설명\r\n","    ---------------------------------------\r\n","    CartoonGAN의 content loss는 feature map에 추가로\r\n","    l1 규제를 취해준다.\r\n","    ---------------------------------------\r\n","    \"\"\"\r\n","    n = photo_feature_map_list.shape[-1]\r\n","    bce = BinaryCrossentropy()\r\n","    error = bce(photo_feature_map_list, cartoonized_photo_feature_map_list).numpy()\r\n","    \r\n","    return error\r\n","\r\n","  # ------------------------------------------------------------------------------------------------------------------------------\r\n","  # content_loss 함수 내용 부분\r\n","\r\n","  model = vgg_transfer_model()\r\n","  photo_feature_map_list = vgg19_transfer_learning(photo_path, model)\r\n","  cartoonized_feature_map_list = vgg19_transfer_learning(cartoonized_photo_path, model)\r\n","  content_loss = l1_regularization(photo_feature_map_list, cartoonized_photo_feature_map_list)\r\n","  \r\n","  return content_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"puinmIePo4l7"},"source":["# total loss\r\n","- $\\mathcal{L}(G, D)$ = $\\mathcal{L}_{adv}(G, D)$ + $w\\mathcal{L}_{con}(G, D)$\r\n"]},{"cell_type":"code","metadata":{"id":"u_OiuHiKpA1S"},"source":["loss = adversarial_loss(disc_c, disc_e, disc_p) + 10 * content_loss(photo_path, cartoonized_photo_path)\r\n","# 논문에서 가중치를 10으로 주었음"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AKerhFnuvc3M"},"source":[""],"execution_count":null,"outputs":[]}]}