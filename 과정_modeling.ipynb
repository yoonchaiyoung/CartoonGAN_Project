{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"과정_modeling.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMBmUfkMFKpn1QD/gnlkvMv"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xDKbUVqsHFz4"},"source":["# CartoonGAN 논문의 모델 구조\r\n","<img src=\"https://aruie.github.io/assets/post/191114-01.png\" width=700>\r\n"]},{"cell_type":"markdown","metadata":{"id":"BuDWFXRHMk2M"},"source":["# generator\r\n","- 초기화 단계 : 10 epoch만큼 먼저 훈련"]},{"cell_type":"markdown","metadata":{"id":"dCN2poXRJPDM"},"source":["## input\r\n","- resizing된 사진 (resizing 함수를 이용하여 300x300으로 미리 resizing)"]},{"cell_type":"code","metadata":{"id":"WSUiS-KRIeoD"},"source":["# Google Drive mount\r\n","from google.colab import drive\r\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iZ3cqQW-If9T"},"source":["# import\r\n","import os\r\n","import matplotlib.pyplot as plt\r\n","import PIL\r\n","import PIL.Image\r\n","import tensorflow as tf\r\n","from matplotlib.image import imread\r\n","import cv2\r\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UMV-HxcpIh3L"},"source":["# 사진 있는 디렉토리 위치\r\n","photo_path = '/content/drive/MyDrive/GoogleColab/CartoonGAN_Project/data/photo_data'\r\n","\r\n","# 사진 파일명 리스트 저장\r\n","photoName_list = os.listdir(photo_path)\r\n","print(photoName_list[:10])  # 앞의 10개만 파일명 보기\r\n","print(len(photoName_list))  # 사진 총 몇 장 있는 지 보기"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lgtN4-hfJUGT"},"source":["## 모델링"]},{"cell_type":"code","metadata":{"id":"uG_blNXyJKY1"},"source":["# 네트워크를 만들 땐\r\n","# 1. sequential 모델을 사용한 네트워크\r\n","# 2. 함수형 API를 사용한 네트워크\r\n","\r\n","# 2가지 방법으로 만들 수 있다.\r\n","\r\n","# 1번 방법 ->  일렬로 층을 쌓은 네트워크를 빠르게 만들 때 사용하기 좋다.\r\n","# 2번 방법 -> 한 층의 출력이 여러 개의 별도의 층으로 전달되는 네트워크를 만들 때 유연성있게 만들기 좋다.\r\n","#          -> 심층 신경망 구조를 설계하는데 자유롭다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHCJspsAJ3bG"},"source":["# 참고 : https://www.tensorflow.org/api_docs\r\n","from keras import layers\r\n","from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, Activation, Dropout, ReLU, Softmax, LeakyReLU, UpSampling2D\r\n","from keras.models import Model\r\n","from keras.losses import BinaryCrossentropy, CategoricalCrossentropy, MAE, MeanSquaredError\r\n","from keras.metrics import Accuracy, CategoricalCrossentropy, MeanSquaredError\r\n","from keras.optimizers import Adam, Optimizer, RMSprop, SGD\r\n","from keras.regularizers import l1, l2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CmZ9pDvZ5Bqc"},"source":["# residual block은 똑같은 구조가 generator안에 8번 반복되므로 함수로 따로 만들자.\r\n","def generator_residual_block(x):\r\n","  shortcut = x\r\n","  x = Conv2D(kernel_size = 3,\r\n","            filters = 256,\r\n","            strides = 1,\r\n","            padding = \"same\"\r\n","            )(x)\r\n","  x = BatchNormalization()(x)\r\n","  x = ReLU()(x)\r\n","  x = Conv2D(kernel_size = 3,\r\n","            filters = 256,\r\n","            strides = 1,\r\n","            padding = \"same\")(x)\r\n","  x = BatchNormalization()(x)\r\n","  x = layers.Add()([x, shortcut])  # identity shortcut connection  # elementwise sum\r\n","  \r\n","  return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gzOKRxk8eY7R"},"source":["up-convolution 영역\r\n","1. UpSampling2D + Conv2D\r\n","2. Conv2DTranspose\r\n","- 두 가지 방법 다 사용해보고 어떤 것이 좋은 결과가 나오는 지 직접 확인해보고 결정해야함\r\n","\r\n","\r\n","- UpSampling2D docs 참고 : https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\r\n","- Conv2DTranspose docs 참고 : https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"LwatunsKkxat"},"source":["## 방법 1 - UpSampling2D + Conv2D 이용"]},{"cell_type":"code","metadata":{"id":"AqIXbO1UKjWa"},"source":["# 우선 input에 사진 이미지를 넣지 않고 숫자만 넣고\r\n","# 틀만 짜보자.\r\n","\r\n","input_shape = (300, 300, 3)\r\n","\r\n","input_layer = Input(shape = input_shape)  # resizing된 사진 넣기\r\n","\r\n","# flat-convolution 영역\r\n","x = Conv2D(kernel_size = 7,\r\n","          filters = 64,\r\n","          strides = 1,\r\n","          padding = \"same\"\r\n","          )(input_layer)\r\n","x = BatchNormalization()(x)\r\n","x = ReLU()(x)\r\n","\r\n","# down-convolution 영역\r\n","x = Conv2D(kernel_size = 3,\r\n","          filters = 128,\r\n","          strides = 2,\r\n","          padding = \"same\"\r\n","          )(x)\r\n","\r\n","model = Model(inputs = input_layer,\r\n","              outputs = x,\r\n","              name = \"generator\")\r\n","x = Conv2D(kernel_size = 3,\r\n","          filters = 128,\r\n","          strides = 1,\r\n","          padding = \"same\"\r\n","          )(x)\r\n","x = BatchNormalization()(x)\r\n","x = ReLU()(x)\r\n","\r\n","x = Conv2D(kernel_size = 3,\r\n","          filters = 256,\r\n","          strides = 2,\r\n","          padding = \"same\"\r\n","          )(x)\r\n","x = Conv2D(kernel_size = 3,\r\n","          filters = 256,\r\n","          strides = 1,\r\n","          padding = \"same\"\r\n","          )(x)\r\n","x = BatchNormalization()(x)\r\n","x = ReLU()(x)\r\n","\r\n","# 8 residual block 영역\r\n","x = generator_residual_block(x)\r\n","x = generator_residual_block(x)\r\n","x = generator_residual_block(x)\r\n","x = generator_residual_block(x)\r\n","x = generator_residual_block(x)\r\n","x = generator_residual_block(x)\r\n","x = generator_residual_block(x)\r\n","x = generator_residual_block(x)\r\n","\r\n","# up-convolution 영역\r\n","x = Conv2D(kernel_size = 3,\r\n","           filters = 256,\r\n","           strides = 1/2,\r\n","           padding = \"same\"\r\n","          )(x)\r\n","x = Conv2D(kernel_size = 3,\r\n","          filters = 128,\r\n","          strides = 1,\r\n","          padding = \"same\"\r\n","          )(x)\r\n","x = BatchNormalization()(x)\r\n","x = ReLU()(x)\r\n","\r\n","x = Conv2D(kernel_size = 3,\r\n","           filters = 64,\r\n","           strides = 1/2,\r\n","           padding = \"same\"\r\n","          )(x)\r\n","x = Conv2D(kernel_size = 3,\r\n","          filters = 64,\r\n","          strides = 1,\r\n","          padding = \"same\"\r\n","          )(x)\r\n","x = BatchNormalization()(x)\r\n","x = LeakyReLU()(x)\r\n","\r\n","# output layer 영역\r\n","x = Conv2D(kernel_size = 7,\r\n","          filters = 3,\r\n","          strides = 1,\r\n","          padding = \"same\"\r\n","          )(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rzxUiUnSB76q"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aVUXohhFk2Ut"},"source":["## 방법2 - Conv2DTranspose 이용"]},{"cell_type":"code","metadata":{"id":"3RdUN4b_Bt3c"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"az0hYPFd69kk"},"source":["# discriminator"]},{"cell_type":"markdown","metadata":{"id":"keZr-XCB6_9R"},"source":["## input\r\n","- 사진\r\n","- 엣지 smoothing된 만화 이미지\r\n","- 카툰화된 사진"]},{"cell_type":"code","metadata":{"id":"VuxqoU_67NCs"},"source":["# 우선 input에 사진 이미지를 넣지 않고 숫자만 넣고\r\n","# 틀만 짜보자."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w2HrNf7A7RPj"},"source":["input_layer = Input((300, 300, 3))\r\n","x = Conv2D(kernel_size = 3,\r\n","           filters = 32,\r\n","           strides = 1,\r\n","           padding = \"same\"\r\n","           )(input_layer)\r\n","x = LeakyReLU()(x)\r\n","\r\n","x = Conv2D(kernel_size = 3,\r\n","           filters = 64,\r\n","           strides = 2,\r\n","           padding = \"same\"\r\n","           )(x)\r\n","x = LeakyReLU()(x)\r\n","x = Conv2D(kernel_size = 3,\r\n","           filters = 128,\r\n","           strides = 1,\r\n","           padding = \"same\"\r\n","           )(x)\r\n","x = BatchNormalization()(x)\r\n","x = LeakyReLU()(x)\r\n","\r\n","x = Conv2D(kernel_size = 3,\r\n","           filters = 128,\r\n","           strides = 2,\r\n","           padding = \"same\"\r\n","           )(x)\r\n","x = LeakyReLU()(x)\r\n","x = Conv2D(kernel_size = 3,\r\n","           filters = 256,\r\n","           strides = 1,\r\n","           padding = \"same\"\r\n","           )(x)\r\n","x = BatchNormalization()(x)\r\n","x = LeakyReLU()(x)\r\n","\r\n","x = Conv2D(kernel_size = 3,\r\n","           filters = 256,\r\n","           strides = 1,\r\n","           padding = \"same\"\r\n","           )(x)\r\n","x = BatchNormalization()(x)\r\n","x = LeakyReLU()(x)\r\n","\r\n","x = Conv2D(kernel_size = 3,\r\n","           filters = 1,\r\n","           strides = 1,\r\n","           padding = \"same\"\r\n","           )(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ecKp639x9EuE"},"source":[""],"execution_count":null,"outputs":[]}]}